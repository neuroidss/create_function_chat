{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOR6AowfJ18Dxozf4AnMmwV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuroidss/create_function_chat/blob/main/create_function_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynZapjfdlQ_h",
        "outputId": "1fe5ed14-0d1b-4e62-9d3f-d0c0725a265e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\n",
            "100 12030    0 12030    0     0  42868      0 --:--:-- --:--:-- --:--:-- 42811\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "process = subprocess.Popen(\"ollama serve\", shell=True)"
      ],
      "metadata": {
        "id": "kocTL74lmTZD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull mistral-nemo:12b-instruct-2407-q6_K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nOGxLFfmERs",
        "outputId": "e4c331ce-e29f-4356-f80c-b2725923704e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 2e6fc37d24f2... 100% ▕▏  10 GB                         \n",
            "pulling f023d1ce0e55... 100% ▕▏  688 B                         \n",
            "pulling 43070e2d4e53... 100% ▕▏  11 KB                         \n",
            "pulling ed11eda7790d... 100% ▕▏   30 B                         \n",
            "pulling 49b9c9265532... 100% ▕▏  486 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "removing any unused layers \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/neuroidss/create_function_chat\n",
        "%cd /content/create_function_chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqRkkrN8m4ZT",
        "outputId": "b631be73-c71c-44bf-87b6-2a829c0ecfe4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'create_function_chat'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 152 (delta 82), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (152/152), 6.31 MiB | 11.12 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "/content/create_function_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhPiO1tSnTHx",
        "outputId": "563a29d3-ff09-4b84-b6a1-2f7a667d58ad"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama) (0.27.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python create_function_chat.py \"call Create function 'description':'Search for articles on arxiv', 'name':'search_arxiv_articles', do not format results, return response text as is\" \"search 2 articles on arxiv about 'increase working memory using EEG'\" \"/exit\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T3QuckJoKYI",
        "outputId": "1ca2979e-2a3d-4722-a018-46d602673ebe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> call Create function 'description':'Search for articles on arxiv', 'name':'search_arxiv_articles', do not format results, return response text as is\n",
            "Here is the Python code for the `search_arxiv_articles` function:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "\n",
            "def search_arxiv_articles(query, start=0, max_results=10):\n",
            "    \"\"\"\n",
            "    Search for articles on arXiv using the given query and return the results as a string.\n",
            "\n",
            "    Args:\n",
            "        query (str): The search query.\n",
            "        start (int, optional): The starting index of the result set. Defaults to 0.\n",
            "        max_results (int, optional): The maximum number of results to return. Defaults to 10.\n",
            "\n",
            "    Returns:\n",
            "        str: A string containing the search results in a formatted way.\n",
            "    \"\"\"\n",
            "    url = \"http://export.arxiv.org/api/query?\"\n",
            "    params = {\n",
            "        \"search_query\": query,\n",
            "        \"start\": start,\n",
            "        \"max_results\": max_results\n",
            "    }\n",
            "    response = requests.get(url, params=params)\n",
            "    if response.status_code == 200:\n",
            "        return response.text\n",
            "    else:\n",
            "        return f\"Error: Unable to fetch data. Status code: {response.status_code}\"\n",
            "\n",
            "# Example usage:\n",
            "result = search_arxiv_articles(\"quantum computing\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "This function sends a GET request to the arXiv API with the provided query, start index, and maximum results. It then returns the raw response text from the API. If there's an error (status code other than 200), it returns an error message.\n",
            "\n",
            "In the example usage, replace `\"quantum computing\"` with your desired search query to retrieve arXiv articles related to that topic.\n",
            ">>> search 2 articles on arxiv about 'increase working memory using EEG'\n",
            "Here are the top two articles on arXiv about 'increase working memory using EEG':\n",
            "\n",
            "1. **Title:** EEG2vec: Self-Supervised Electroencephalographic Representation Learning\n",
            "   - **Authors:** Qiushi Zhu, Xiaoying Zhao, Jie Zhang, Yu Gu, Chao Weng, Yuchen Hu\n",
            "   - **Published on:** May 23, 2023\n",
            "   - **Summary:** This paper introduces a self-supervised model based on contrastive loss and reconstruction loss to learn EEG representations. The pre-trained model is then used as a feature extractor for downstream tasks. The effectiveness of the method is demonstrated on the EEG match-mismatch and EEG regression tasks of the ICASSP2023 Auditory EEG Challenge.\n",
            "   - **Link:** [https://arxiv.org/abs/2305.13957](https://arxiv.org/abs/2305.13957)\n",
            "\n",
            "2. **Title:** A LSTM-RNN Approach to Investigate Temporal Dynamics in Human EEG Data in Encoding Working Memory Load Information\n",
            "   - **Authors:** Samuel Goldstein, Zhenhong Hu, Mingzhou Ding\n",
            "   - **Published on:** October 16, 2019\n",
            "   - **Summary:** This study applies a LSTM-RNN approach to investigate temporal dynamics in human EEG data when encoding working memory load information. It's the first study of its kind, to the best of their knowledge.\n",
            "   - **Link:** [https://arxiv.org/abs/1910.05621](https://arxiv.org/abs/1910.05621)\n",
            ">>> /exit\n"
          ]
        }
      ]
    }
  ]
}